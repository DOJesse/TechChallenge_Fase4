# Tech Challenge Fase 4

## ğŸ“– DescriÃ§Ã£o
Esta aplicaÃ§Ã£o Ã© uma **API RESTful** desenvolvida em Flask que utiliza um modelo **LSTM** para prever o fechamento de aÃ§Ãµes com base em dados histÃ³ricos.  
O fluxo completo inclui:  
1. **Download** dos dados de mercado com `yfinance`.  
2. **PrÃ©-processamento** e **treinamento** do modelo LSTM.  
3. **Deploy** da API para receber CSVs de histÃ³rico e retornar previsÃµes.  
4. **Monitoramento** em produÃ§Ã£o via Prometheus & Grafana. 

---

## ğŸ“‚ Estrutura do Projeto

```text
â”œâ”€â”€ downloadData/
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â””â”€â”€ <SYMBOL>_data.csv        # Dados histÃ³ricos baixados
â”‚   â””â”€â”€ downloadData.py              # Script de download de dados
â”‚
â”œâ”€â”€ modelTraining/
â”‚   â””â”€â”€ train_lstm.py                # Script de treino do modelo LSTM
â”‚
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â””â”€â”€ app.py                   # CÃ³digo principal da API Flask
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â””â”€â”€ lstm_model.py            # ImplementaÃ§Ã£o do modelo LSTM
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â””â”€â”€ prediction_service.py    # ServiÃ§o de prediÃ§Ã£o
â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â””â”€â”€ metrics.py               # MÃ©tricas Prometheus
â”‚   â”œâ”€â”€ templates/
â”‚   â”‚   â””â”€â”€ upload.html              # FormulÃ¡rio de upload CSV
â”‚   â”œâ”€â”€ config.py                    # ConfiguraÃ§Ãµes da aplicaÃ§Ã£o
â”‚   â””â”€â”€ pyproject.toml               # DependÃªncias e scripts (Poetry)
â”‚
â”œâ”€â”€ grafana/                         # Dashboards e provisioning do Grafana
â”‚   â”œâ”€â”€ dashboards/
â”‚   â””â”€â”€ provisioning/
â”‚
â”œâ”€â”€ Docker/                          # Dockerfile e docker-compose
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”œâ”€â”€ docker-compose.yml
â”‚   â””â”€â”€ requirements.txt
â”‚
â””â”€â”€ README.md                        # Este arquivo
```

---

## âš™ï¸ PrÃ©-requisitos
- Docker & Docker Compose  
- Python 3.8+ (se for treinar localmente)  
- Poetry (gerenciamento de dependÃªncias) 

---

## ğŸš€ Passo a Passo

### 1. Baixar dados histÃ³ricos
```bash
cd downloadData
python downloadData.py
```
Isso gera um CSV em `downloadData/data/<SYMBOL>_data.csv`. 

### 2. Treinar o modelo LSTM (opcional)
```bash
cd modelTraining
python train_lstm.py
```
O script consome o CSV, faz prÃ©-processamento, cria sequÃªncias, treina e salva:
- `app/model/model_lstm.keras`  
- `app/model/scaler.pkl` 

### 3. Executar a aplicaÃ§Ã£o localmente
```bash
cd app
poetry install
poetry run python -m api.app
```
- **API Flask** âœ http://localhost:5001 

### 4. Subir toda a stack em containers
```bash
cd Docker
docker-compose up --build
```
- **API Flask** âœ http://localhost:5001  
- **Prometheus** âœ http://localhost:9090  
- **Grafana** âœ http://localhost:3000 

---

## ğŸ“¡ Uso da API

### ğŸ“ Upload de CSV
1. Acesse http://localhost:5001/  
2. Envie um arquivo CSV com colunas `Date, Open, High, Low, Close, Volume`.  
3. O JSON de resposta conterÃ¡ `predicted_close`. 

### ğŸ“ˆ PrevisÃ£o B3 (10 maiores empresas)
1. **Via GET**  
   ```
   http://localhost:5001/predict_b3?company=<Empresa>
   ```
2. **Via POST** (JSON)
   ```json
   { "company": "Petrobras (PETR4)" }
   ```
3. ParÃ¢metro `company` deve ser um dos nomes abaixo:
   - Petrobras (PETR4)  
   - ItaÃº Unibanco (ITUB4)  
   - Vale S.A. (VALE3)  
   - Ambev (ABEV3)  
   - BTG Pactual (BPAC11)  
   - Weg (WEGE3)  
   - Bradesco (BBDC4)  
   - Banco do Brasil (BBAS3)  
   - ItaÃºsa (ITSA4)  
   - Santander Brasil (SANB11)  
4. Exemplo GET:
   ```
   http://localhost:5001/predict_b3?company=Vale%20S.A.%20(VALE3)
   ```  
Resposta:
```json
{ "company": "Vale S.A. (VALE3)", "predicted_close": 105.23 }
```  
î€… Para mais detalhes de implementaÃ§Ã£o, veja `app.py` 

---

## ğŸ“Š Monitoramento & Dashboards Grafana

Para acompanhar tempo de resposta, consumo de recursos e inferÃªncia:

### Infraestrutura do Processo Python
- **CPU (mÃ©dia 5m)**
  ```promql
  rate(process_cpu_seconds_total[5m])
  ```
- **MemÃ³ria residente (RSS)**
  ```promql
  process_resident_memory_bytes
  ```
- **GC por minuto**
  ```promql
  rate(python_gc_objects_collected_total[1m])
  ``` 

### MÃ©tricas HTTP da API
- **RequisiÃ§Ãµes (1m)**
  ```promql
  sum(rate(http_requests_total[1m])) by (method, status)
  ```
- **LatÃªncia 95Âº perc. (5m)**
  ```promql
  histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket[5m])) by (le))
  ``` 

### MÃ©tricas de InferÃªncia do Modelo
- **LatÃªncia inferÃªncia 50Âº perc.**
  ```promql
  histogram_quantile(0.50, sum(rate(model_inference_duration_seconds_bucket[5m])) by (le))
  ```
- **LatÃªncia inferÃªncia 95Âº perc.**
  ```promql
  histogram_quantile(0.95, sum(rate(model_inference_duration_seconds_bucket[5m])) by (le))
  ```
- **Taxa de prediÃ§Ãµes (1m)**
  ```promql
  sum(rate(model_predictions_total[1m]))
  ```
- **MAE Ãºltimas 1h**
  ```promql
  avg_over_time(model_prediction_error_absolute[1h])
  ``` 

---

## ğŸ“ Dicas de OrganizaÃ§Ã£o no Grafana
- Agrupe **CPU**, **MemÃ³ria** e **GC** em â€œHealthâ€.  
- Coloque **RequisiÃ§Ãµes** e **LatÃªncia HTTP** em â€œAPI Performanceâ€.  
- Separe **InferÃªncia** em â€œModel Monitoringâ€.  
- Ajuste intervalos (e.g. 5m, 1h) conforme necessidade.